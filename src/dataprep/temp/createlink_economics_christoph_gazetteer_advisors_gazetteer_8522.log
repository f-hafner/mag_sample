/home/christoph/anaconda3/envs/science-career-tempenv/lib/python3.9/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/christoph/anaconda3/envs/science-career-tempenv/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/christoph/anaconda3/envs/science-career-tempenv/lib/python3.9/site-packages/numpy/core/getlimits.py:500: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/christoph/anaconda3/envs/science-career-tempenv/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
Namespace(testing=False, verbose=1, field=['economics'], train_name='christoph_gazetteer', startyear=1985, endyear=2022, loadstartyear=1985, loadendyear=2022, mergemode='1:1', recall=0.9, institution='True', fieldofstudy_cat='False', fieldofstudy_str='False', keywords='False', retrain='True', linking_type='advisors', samplesize=100000, write_to='csv')
Have max 6 cores available
Testing is False 

I set the write connection to temporary database.
id_field is [162324750] and will be passed to sql queries.

        SELECT relationship_id
                , year
                , year AS year_range
                , firstname 
                , lastname
                , CASE TRIM(SUBSTR(middle_lastname, 1, l_fullname-l_firstname-l_lastname - 1)) 
                    WHEN 
                        "" THEN NULL 
                        ELSE TRIM(SUBSTR(middle_lastname, 1, l_fullname-l_firstname-l_lastname - 1)) 
                    END AS middlename
                , fieldofstudy
                , keywords
                , institution
                , year || "//" || institution as main_us_institutions_year
                , year || "//" || institution as all_us_institutions_year
        FROM (
            SELECT goid
                , relationship_id
                , degree_year AS year 
                , a.fullname 
                , SUBSTR(TRIM(a.fullname),1,instr(trim(a.fullname)||' ',' ')-1) AS firstname
                , REPLACE(a.fullname, RTRIM(a.fullname, REPLACE(a.fullname, " ", "")), "") AS lastname 
                , TRIM(SUBSTR(a.fullname, length(SUBSTR(TRIM(a.fullname),1,instr(trim(a.fullname)||' ',' ')-1)) + 1)) AS middle_lastname 
                , length(a.fullname) AS l_fullname 
                , length(SUBSTR(TRIM(a.fullname),1,instr(trim(a.fullname)||' ',' ')-1) ) AS l_firstname
                , length(REPLACE(a.fullname, RTRIM(a.fullname, REPLACE(a.fullname, " ", "")), "")) AS l_lastname
                , fieldname AS fieldofstudy
                , university_id
            FROM pq_authors 
            INNER JOIN (
                SELECT goid, fieldname 
                FROM pq_fields_mag
                WHERE mag_field0 IN (?)
            ) USING (goid)
            INNER JOIN ( --# NOTE: this only keeps the theses where at least one advisor is present
                SELECT *, firstname || ' ' || lastname AS fullname
                FROM pq_advisors
            ) AS a USING(goid)
        )
        -- ## NOTE: use left join here as not all graduates have advisor (particularly pre-1980) and possibly also keywords
        LEFT JOIN (
            SELECT goid
                , fields as keywords
            FROM pq_info_linking
        ) USING(goid) 
        INNER JOIN (
            SELECT university_id, normalizedname as institution
            FROM pq_unis --## mark: previously we linked advisors anywhere in the world (as career outcomes). for now, focus on US
            WHERE location like "%United States%"
        ) USING(university_id)
        WHERE year >= 1985 and year <= 2022 AND length(firstname) > 1
         


    SELECT f.AuthorId
        , f.year
        , f.YearLastPub
        , f.firstname
        , f.lastname
        , CASE TRIM(SUBSTR(f.middle_lastname, 1, f.l_fullname - f.l_firstname - f.l_lastname - 1)) 
            WHEN 
                "" THEN NULL 
                ELSE TRIM(SUBSTR(f.middle_lastname, 1, f.l_fullname - f.l_firstname - f.l_lastname - 1)) 
            END as middlename 
            -- ## NOTE this gives "" for middlename when it is missing 
        , f.fieldofstudy
        , g.keywords
        , g.coauthors
        , g.institution
        , g.main_us_institutions_year
         
        , f.year || ";" || f.YearLastPub AS year_range 
        , g.all_us_institutions_year
    
    FROM (
        SELECT a.AuthorId
            , a.YearFirstPub AS year
            , a.YearLastPub 
            , a.FirstName AS firstname
            , REPLACE(b.NormalizedName, RTRIM(b.NormalizedName, REPLACE(b.NormalizedName, " ", "")), "") AS lastname 
                    -- https://stackoverflow.com/questions/21388820/how-to-get-the-last-index-of-a-substring-in-sqlite
            , TRIM(SUBSTR(b.NormalizedName, length(a.FirstName) + 1)) AS middle_lastname 
                    -- this gives all except the first name 
            , length(b.NormalizedName) as l_fullname 
            , length(a.FirstName) as l_firstname
            , length(REPLACE(b.NormalizedName, RTRIM(b.NormalizedName, REPLACE(b.NormalizedName, " ", "")), "")) as l_lastname
            , e.NormalizedName AS fieldofstudy
        FROM author_sample AS a
        INNER JOIN (
            SELECT AuthorId, NormalizedName
            FROM Authors
        ) AS b USING(AuthorId)
        INNER JOIN (
            SELECT AuthorId
            FROM author_field0
            WHERE FieldOfStudyId_lvl0 IN (?)
                AND Degree <= 0
        ) USING(AuthorId)
        LEFT JOIN (
            SELECT AuthorId, NormalizedName
            FROM author_fields c
            INNER JOIN (
                SELECT FieldOfStudyId, NormalizedName
                FROM FieldsOfStudy
            ) AS d USING(FieldOfStudyId)
            -- ## Condition on fieldofstudy being in the level 0 id_field
            INNER JOIN (
                SELECT ParentFieldOfStudyId, ChildFieldOfStudyId
                FROM crosswalk_fields
                WHERE ParentLevel = 0
                    AND ParentFieldOfStudyId IN (?)
            ) AS e ON (e.ChildFieldOfStudyId = c.FieldOfStudyId)
            WHERE FieldClass = 'first'
        ) AS e USING(AuthorId)
    ) f
    LEFT JOIN (
        SELECT AuthorId
                , main_us_institutions_career as institution
                , coauthors
                , keywords
                , main_us_institutions_year
                , all_us_institutions_year
        FROM author_info_linking
    ) AS g USING(AuthorId)
    
    WHERE length(firstname) > 1 AND year >= 1985 - 5 AND year <= 2022 + 5 AND institution is not NULL
     

reading from:  /mnt/ssd/DedupeFiles/advisors/settings_economics_1985_2022_institutionTrue_fieldofstudy_catFalse_fieldofstudy_strFalse_keywordsFalsechristoph_gazetteer
index canonical data ...
Search in linker now ... 
Writing to database...
Filling table info...
Filled table info...
Iteration id is 77
Filling links into db...
0it [00:00, ?it/s]1it [10:08, 608.01s/it]4552it [10:08, 10.69it/s]9766it [10:08, 28.18it/s]14840it [10:08, 52.47it/s]14840it [10:22, 52.47it/s]16850it [13:45, 26.64it/s]23529it [13:45, 52.88it/s]30318it [13:45, 90.96it/s]36387it [13:45, 139.49it/s]36387it [14:02, 139.49it/s]36850it [15:37, 63.69it/s] 42094it [15:37, 101.33it/s]47690it [15:37, 158.60it/s]53158it [15:37, 238.31it/s]53158it [15:52, 238.31it/s]56850it [20:35, 43.66it/s] 61261it [20:35, 61.86it/s]66282it [20:35, 91.42it/s]71409it [20:35, 134.49it/s]76638it [20:35, 197.11it/s]81741it [20:36, 282.40it/s]135998it [20:36, 109.99it/s]
now we have a list and will write that into db
Filled links into db...
Wrote linking info into db...
Running ANALYZE... 

Copying to csv...
Done copying to csv...
Deleted the temporary database...
Done in 28.938795590400694 minutes.
