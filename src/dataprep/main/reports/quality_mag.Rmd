---
title: "Some exploration of MAG data quality"
author: "Flavio Hafner (minor changes by Christoph)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(1234)
```

```{r, echo = FALSE, include = FALSE}
packages <- c("tidyverse", "broom", "dbplyr", "RSQLite", "ggplot2",
              "furrr", "tictoc", "parallel")

lapply(packages, library, character.only = TRUE)

db_file  <- "/mnt/ssd/AcademicGraph/AcademicGraph.sqlite"
cutoff_hhi <- 0.15 # above this, an author is considered to be at least 
                    # moderately specialized in one field
start_year <- 1950 
end_year <- 2015

# ## db connection
con <- DBI::dbConnect(RSQLite::SQLite(), db_file)
cat("The database connection is: \n")
src_dbi(con)

n_cores <- detectCores()
n_cores_to_use <- n_cores / 2

```


```{r, include = FALSE}
query <- paste0(
"
    SELECT *
    FROM author_fields
    INNER JOIN (
        SELECT AuthorId,
                YearFirstPub,
                (YearLastPub - YearFirstPub) AS CareerLength,
                PaperCount AS CareerPaperCount
        FROM author_sample
        WHERE YearFirstPub >= ", start_year, " AND 
            YearFirstPub <= ", end_year, "
    ) USING (AuthorId)
"  
)

# use 2015 so that newly entering cohorts had some time to publish a few papers
author_fields <- tbl(con, sql(query)) %>%
    collect() %>%
    mutate(hhi_norm = (HHIAllFields - 1 / FieldOfStudyCount) /
                        (1 - 1 / FieldOfStudyCount),
          hhi_norm = ifelse(FieldOfStudyCount == 1, 1, hhi_norm),
          cohort = 10 * floor(YearFirstPub / 10))
missing_fields <- author_fields %>% 
  mutate(field_missing = ifelse(is.na(FieldOfStudyId), 1, 0)) %>% 
  group_by(FieldClass, field_missing) %>% 
  summarise(n_authors = n(),
            mean_career_length = mean(CareerLength),
            mean_paper_count = mean(CareerPaperCount),
            .groups = "drop")

author_fields <- author_fields %>% 
  filter(!is.na(FieldOfStudyId))

author_fields_agg <- author_fields %>%
    group_by(FieldClass, cohort) %>%
    summarise(hhi_mn = mean(hhi_norm),
              hhi_q10 = quantile(hhi_norm, 0.1),
              share_mn = mean(Score / SumScoreAllFields),
              share_md = median(Score / SumScoreAllFields),
              n_fields_mn = mean(FieldOfStudyCount),
              n_fields_md = median(FieldOfStudyCount),
              share_concentrated = mean(hhi_norm > cutoff_hhi),
              CareerLength_mn = mean(CareerLength),
              career_publication_rate_mn =
                mean(CareerPaperCount / CareerLength),
              n_authors = n(),
              n_years_cohort = n_distinct(YearFirstPub),
              .groups = "drop")

```

```{r, include=TRUE}
cat("Distribution of authors across FieldClass by missing FieldOfStudyId: \n")
print(missing_fields)
cat("Authors with missing fields are dropped from now.")
```


## Aggregate statistics by cohort 

### Average number of new authors per year 
```{r, echo = FALSE}
ggplot(author_fields_agg %>% filter(FieldClass == "main"),
       aes(x = cohort, y = n_authors / n_years_cohort)) +
    geom_line() +
    geom_point()

```

### Average career length
```{r, echo = FALSE}
ggplot(author_fields_agg %>% filter(FieldClass == "main"),
       aes(x = cohort, y = CareerLength_mn)) +
    geom_line() +
    geom_point() +
    facet_wrap(~FieldClass)

```


### Average career publication rate 
```{r, echo = FALSE}
ggplot(author_fields_agg %>% filter(FieldClass == "main"),
       aes(x = cohort, y = career_publication_rate_mn)) +
    geom_line() +
    geom_point()

```


### Career length

- 10 percent subsample of authors
- The "discontinuous" drop in career length density is at 6 years


```{r, echo = FALSE}
author_fields %>%
    filter(FieldClass == "main") %>%
    group_by(cohort) %>%
    slice_sample(prop = 0.1) %>%
    ggplot() +
    geom_histogram(aes(x = CareerLength)) +
    facet_wrap(~cohort)
```


## Author count and gender share by field-cohort and region-cohort

- region is assigned based on the Iso3166 Code of the author's first affiliation

```{r, include = FALSE}

# first known affiliation by author
query_first_affiliation <- "
SELECT *
FROM (
  SELECT AuthorId
        , AffiliationId AS FirstKnownAffiliationId
        , Iso3166Code
        , YearFirstKnownAffiliation
  FROM (
    SELECT a.AuthorId
          , a.AffiliationId
          , a.Year
          , b.Iso3166Code
          , MIN(a.Year) OVER(PARTITION BY a.AuthorId)
              AS YearFirstKnownAffiliation
    FROM AuthorAffiliation a
    INNER JOIN (
      SELECT AffiliationId, Iso3166Code
      FROM Affiliations
    ) b USING(AffiliationId)
  )
  WHERE Year = YearFirstKnownAffiliation
)
GROUP BY AuthorId
"

query <- "SELECT a.AuthorId
                , b.YearFirstPub, b.PersonCount, b.ProbabilityFemale, b.ProbabilityFemaleNew
                , c.NormalizedName AS FieldName  
          FROM author_fields a 
          INNER JOIN (
            SELECT c.*, d.PersonCount, d.ProbabilityFemale, e.ProbabilityFemaleNew
            FROM author_sample c
            INNER JOIN FirstNamesGender d USING(FirstName)
            LEFT JOIN (
                SELECT AuthorId, ProbabilityFemale AS ProbabilityFemaleNew
                FROM author_gender
            ) e USING (AuthorId)
          ) b USING(AuthorId) 
          INNER JOIN FieldsOfStudy c USING(FieldOfStudyId)
          WHERE a.FieldClass = 'main'
          "

author_country <- tbl(con, sql(query_first_affiliation))
author_field_gender <- tbl(con, sql(query)) %>% 
  filter(YearFirstPub >= start_year) %>%
  mutate(cohort = 10 * floor(YearFirstPub / 10),
         ProbFemale = case_when(ProbabilityFemale >= .8 ~ "[0.8, 1]",
                                ProbabilityFemale > .5 ~ "(0.5, 0.8]",
                                ProbabilityFemale > .2 ~ "(0.2, 0.5]",
                                ProbabilityFemale <= .2 ~ "[0, 0.2]"),
         ProbFemaleNew = case_when(ProbabilityFemaleNew >= .8 ~ "[0.8, 1]",
                                    ProbabilityFemale > .5 ~ "(0.5, 0.8]",
                                    ProbabilityFemaleNew > .2 ~ "(0.2, 0.5]",
                                    ProbabilityFemaleNew <= .2 ~ "[0, 0.2]")) %>%
  # the new gender assignment omits records where ProbFemale is ambiguous and ProbFemaleNew does not do better
  mutate(ProbFemaleNew = ifelse(is.na(ProbFemaleNew), ProbFemale, ProbFemaleNew)) 
```

```{r, include=FALSE}

sumstat_field_country <- author_field_gender %>% 
  left_join(author_country %>%
               select(AuthorId, Iso3166Code), 
             by = "AuthorId") %>%
  group_by(ProbFemale, ProbFemaleNew, cohort, FieldName, Iso3166Code) %>%
  summarise(nb = n(), .groups = "drop") %>%
  collect() %>% 
  mutate(across(all_of(c("ProbFemale", "ProbFemaleNew")),
                ~ifelse(is.na(.), "missing", .))) %>% 
  filter(cohort < 2020)

```


```{r, include=FALSE}

# selection of supposedly largest countries in terms of researchers
  # note: 3.7 Mio authors do not have any known firstaffiliationid
codes_english <- c("GB", "US", "AU", "CA", "IE", "NZ")
codes_europe <- c("FR", "DE", "IT", "ES", "CH", "BE", "NL", 
                  "DK", "NO", "SE", "FI", "EE", "LV", "LT",
                  "BY", "RU",
                  "PL", "CZ", "AT", "RO", "HR", "RS",
                  "HU", "GR")
codes_asia <- c("JP", "CN", "TW", "KP", "KR", "IN", 
                "SG", "TH", "MY")
codes_southam <- c("AR", "BR", "CL", "CO", "MX")
factor_levels <- c("English speaking", "Europe non-English",
                   "Asia", "South America", "Unknown", "Other")

sumstat_field_country <- sumstat_field_country %>%
  mutate(
    region = case_when(
      Iso3166Code %in% codes_europe ~ "Europe non-English",
      Iso3166Code %in% codes_english ~ "English speaking",
      Iso3166Code %in% codes_southam ~ "South America",
      Iso3166Code %in% codes_asia ~ "Asia",
      is.na(Iso3166Code) | Iso3166Code == "" ~ "Unknown"
      ),
    region = ifelse(is.na(region), "Other", region),
    region = factor(region, levels = factor_levels)) 

```

```{r, include=FALSE}
sumstat_field <- sumstat_field_country %>% 
  group_by(ProbFemale, cohort, FieldName) %>% 
  summarise(nb = sum(nb), .groups = "drop") 

sumstat_region <- sumstat_field_country %>% 
  group_by(ProbFemale, cohort, region) %>% 
  summarise(nb = sum(nb), .groups = "drop")

sumstat_region_gender_newold <- sumstat_field_country %>% 
  # consolidate
  mutate(across(all_of(c("ProbFemale", "ProbFemaleNew")),
                ~ifelse(. %in% c("(0.5, 0.8]",  "(0.2, 0.5]"),
                        "other",
                        .))) %>% 
  group_by(ProbFemale, ProbFemaleNew, cohort, region) %>% 
  summarise(nb = sum(nb), .groups = "drop") 


```

### By field-cohort
#### Number of authors by assigned gender
```{r, echo = FALSE}

sumstat_field %>% 
  group_by(cohort, ProbFemale) %>% 
  summarise(nb = sum(nb), .groups = "drop") %>% 
  ggplot(aes(x = cohort, y = nb, fill = ProbFemale)) + 
  geom_bar(stat = "identity") +
  theme(legend.position = "bottom") + 
  labs(y = "Author count", fill = "P(female)")
```

#### Number of authors
```{r, echo = FALSE}
sumstat_field %>% 
  group_by(cohort, FieldName) %>% 
  summarise(nb = sum(nb),.groups = "drop") %>% 
  ggplot(aes(x = cohort, y = nb)) + 
  geom_line(aes(color = FieldName))

```

#### Fraction by gender 
```{r, echo = FALSE}
sumstat_field %>% 
  # filter(gender != "missing") %>% 
  group_by(cohort, FieldName) %>% 
  mutate(s = nb / sum(nb)) %>% 
  ggplot(aes(x = cohort, y = s)) + 
  geom_line(aes(linetype = ProbFemale, color = ProbFemale)) + 
  facet_wrap(~FieldName)  +
  theme_bw() + 
  theme(legend.position = "bottom") + 
  labs(y = "Share")
```


### By region-cohort
#### Number of authors 
```{r, echo=FALSE}
sumstat_region %>% 
  group_by(cohort, region) %>% 
  summarise(nb = sum(nb),.groups = "drop") %>% 
  ggplot(aes(x = cohort, y = nb)) + 
  geom_line(aes(color = region)) +
  theme(legend.position = "bottom")
```



#### Fraction by gender
```{r, echo=FALSE}
sumstat_region %>% 
  # filter(gender != "missing") %>% 
  group_by(cohort, region) %>% 
  mutate(s = nb / sum(nb)) %>% 
  ggplot(aes(x = cohort, y = s)) + 
  geom_line(aes(linetype = ProbFemale, color = ProbFemale)) + 
  facet_wrap(~region)  +
  theme_bw() + 
  theme(legend.position = "bottom") + 
  labs(y = "Share")
```

#### Comparing new and old gender assigment 
```{r, echo=FALSE}

bind_rows(
  sumstat_region_gender_newold %>% 
    group_by(cohort, region, ProbFemale) %>% 
    summarise(nb = sum(nb), .groups = "drop") %>% 
    mutate(method = "Only first names"),
  sumstat_region_gender_newold %>% 
    group_by(cohort, region, ProbFemaleNew) %>% 
    summarise(nb = sum(nb), .groups = "drop") %>% 
    mutate(method = "Other parts of name") %>% 
    rename(ProbFemale = ProbFemaleNew)
) %>% 
  group_by(cohort, region, method) %>% 
  mutate(s = nb / sum(nb)) %>% 
  ggplot(aes(x = cohort, y = s)) + 
  geom_line(aes(linetype = ProbFemale, color = ProbFemale)) + 
  facet_grid(method~region)  +
  theme_bw() + 
  theme(legend.position = "bottom") + 
  labs(y = "Share")
```





## How good is the assignment of authors to fields? Aggregate statistics by cohort and FieldClass

### Average count of FieldOfStudyId per AuthorId-FieldClass by cohort
```{r, echo = FALSE}
ggplot(author_fields_agg,
       aes(x = cohort, y = n_fields_mn)) +
    geom_line() +
    geom_point() +
    facet_wrap(~FieldClass)
```

### Average Herfindahl index per author

- The index measures how much an author specializes in a specific field
- The figure plots the [normalized HHI](https://en.wikipedia.org/wiki/Herfindahl%E2%80%93Hirschman_Index)


```{r, echo = FALSE}
ggplot(author_fields_agg,
       aes(x = cohort, y = hhi_mn)) +
    geom_line() +
    geom_point() +
    facet_wrap(~FieldClass)

```

### Share of authors with "moderate" or "high" concentration in a field
```{r, echo = FALSE}
 ggplot(author_fields_agg,
        aes(x = cohort, y = share_concentrated)) +
    geom_line() +
    geom_point() +
    facet_wrap(~FieldClass)
```



### Normalized HHI

- 10 percent subsample of authors by FieldClass-cohort
- The red line indicates the threshold for moderate concentration


```{r, echo = FALSE}
author_fields %>%
    group_by(FieldClass, cohort) %>%
    slice_sample(prop = 0.1) %>%
    ggplot() +
    geom_histogram(aes(x = hhi_norm)) +
    facet_grid(FieldClass~cohort) +
    geom_vline(xintercept = cutoff_hhi, color = "red")

```


### Who are these authors with very low HHI? 

- Short careers? random publications?
  - random publications are taken care of with the sample restriction imposed on `author_sample` table
- Why does the fraction of such authors grow over time?

```{r, echo = FALSE}
m <- lm(HHIAllFields ~ 
          log(CareerLength) + factor(cohort) + log(CareerPaperCount),
        data = author_fields %>% 
          filter(FieldClass == "first") %>%
          slice_sample(prop = 0.01)
        )
summary(m)
```


# MAG institution coverage over time

Define some functions

- keep authors and their publication when they are in author_sample


```{r}


make_year_query <- function(year) {
  query = paste0("
      SELECT a.PaperId, b.AuthorId, a.Year, a.DocType, c.AffiliationName
      FROM Papers a
      INNER JOIN (
          SELECT PaperId, AuthorId, AffiliationId
          FROM PaperAuthorAffiliations
      ) b USING(PaperId)
      LEFT JOIN (
          SELECT AffiliationId, NormalizedName AS AffiliationName
          FROM Affiliations
      ) c USING(AffiliationId)
      INNER JOIN (
        SELECT AuthorId
        FROM author_sample
      ) USING(AuthorId)
      WHERE Year = ", year, " and DocType in ('Journal', 'Book', 'BookChapter', 'Conference')")
  return(query)
}

summarise_counts <- function(d) {
  
  # by author
  by_author <- d %>%
    group_by(Year, AuthorId) %>% 
    summarise(has_affiliation = any(!is.na(AffiliationName)),
              .groups = "drop") %>%
    group_by(Year, has_affiliation) %>% 
    summarise(nb = n(),
              .groups = "drop") 


  # by paper-doctype
  by_paper <- d %>%
    group_by(PaperId, Year, DocType) %>%
    summarise(has_affiliation = any(!is.na(AffiliationName)),
              .groups = "drop") %>%
    group_by(Year, DocType, has_affiliation) %>%
    summarise(nb = n(),
              .groups = "drop")

  # by author-paper-doctype
  by_author_paper <- d %>% 
    group_by(PaperId, AuthorId, Year, DocType) %>%
    mutate(has_affiliation = ifelse(any(!is.na(AffiliationName)), 1, 0)) %>%
    ungroup() %>%
    filter(!duplicated(paste0(PaperId, AuthorId))) %>%
    group_by(Year, DocType) %>%
    summarise(author_paper_count = n(),
              count_with_affiliation = sum(has_affiliation),
              .groups = "drop")
  
  out <- list(
    by_author = by_author,
    by_paper = by_paper,
    by_author_paper = by_author_paper
  )

  return(out)
}



get_summary <- function(year) {
  cat(year, "\n--------\n")
  q <- make_year_query(year)
  data <- tbl(con, sql(q)) %>% collect()
  
  agg <- summarise_counts(data)
  return(agg)
}


get_summary_parallel <- function(year) {
  pcon <- DBI::dbConnect(RSQLite::SQLite(), db_file)
  q <- make_year_query(year)
  data <- tbl(pcon, sql(q)) %>% collect()
  DBI::dbDisconnect(pcon)

  agg <- summarise_counts(data)
  
  return(agg)
}



```



Parallel queries and summarise

- only querying subset of years should be fine for capturing trends


```{r}

years = seq(1950, 2020, 5)

plan(multisession, workers = n_cores_to_use)

tic()
d_ls <- future_map(.x = years,
                   .f = ~get_summary_parallel(.x),
                   .options = furrr_options(chunk_size = 1, seed = TRUE)
                   )
toc()

plan(sequential)


```

Collect data

```{r}

df_names <- c("by_author", "by_paper", "by_author_paper")
d_collected <- map(.x = df_names,
                   .f = ~map(
                     .x = d_ls,
                     .f = ~.x[[.y]],
                     .y = .x
                   ) %>%
                     bind_rows()
                   )

names(d_collected) <- df_names


```


### Fraction of author-paper combinations with non-missing affiliation

```{r}

d_collected$by_author_paper %>%
  ggplot(aes(x = Year, y = count_with_affiliation/author_paper_count),
         group = DocType) + 
  geom_line(aes(linetype = DocType)) + 
  geom_point(aes(shape = DocType)) +
  theme(legend.position = "bottom")

```

### Fraction of papers with non-missing affiliation

```{r}

d_collected$by_paper %>%
  mutate(has_affiliation = ifelse(has_affiliation, "yes", "no")) %>%
  spread(key = has_affiliation, value = nb) %>%
  ggplot(aes(x = Year, y = yes/(yes + no)),
         group = DocType) +
  geom_line(aes(linetype = DocType)) +
  geom_point(aes(shape = DocType)) +
  theme(legend.position = "bottom") + 
  labs(y = paste0("Share papers"))

```

### Fraction of authors with non-missing affiliation

```{r}
d_collected$by_author %>%
  mutate(has_affiliation = ifelse(has_affiliation, "yes", "no")) %>%
  spread(key = has_affiliation, value = nb) %>%
  ggplot(aes(x = Year, y = yes/(yes + no))) +
  geom_line() +
  geom_point() +
  theme(legend.position = "bottom") + 
  labs(y = "Share of authors")


```

### What do we learn?

- At first sight, the coverage of affiliations seems low
- But we would like to know the stats for a more selected sample: authors in US
  - Also remember that MAG covers more documents than other sources
- How can we get closer to what we want to measure?
  - perhaps we could measure the fraction of authors in our graduate-mag linked sample that have an affiliation over time?
  - since we did not use the affiliation as a feature for linking, this could work


```{r, include = FALSE}
DBI::dbDisconnect(con)
```





